\chapter{Nozioni Fondamentali}

L'obiettivo di questo capitolo è quello di presentare i concetti di base che vengono utilizzati nel seguito di questo
lavoro e, più in generale, nell'ambito dell'ottimizzazione matematica.

\section{Introduzione}
Nel corso della sua esistenza, l’uomo ha sempre dovuto affrontare e risolvere una grande varietà di problemi. Con il
passare del tempo, le nostre capacità si sono evolute e gli strumenti a nostra disposizione sono migliorati,
permettendoci di gestire problemi di complessità sempre maggiore. Di conseguenza, oggi non ci accontentiamo più di
risolvere un problema trovando una soluzione arbitraria, ma aspiriamo ad ottimizzare, cioè a identificare la soluzione
migliore possibile, sulla base di criteri specifici.

L'ottimizzazione è ormai parte integrante di tutti gli ambiti che richiedano di risolvere problemi decisionali. Nella
pratica, risolvere un problema decisionale significa assegnare valori alle variabili che lo caratterizzano. In molti
casi, la scelta di questi valori è limitata da un insieme di vincoli che devono essere soddisfatti. L'obiettivo è quello
di ottimizzare una grandezza specifica. Questa grandezza e i vincoli da soddisfare possono spesso essere rappresentati
come funzioni delle variabili coinvolte, permettendoci di definire il problema utilizzando un modello matematico. La
formulazione di un modello dovrebbe essere sufficientemente complessa da rappresentare accuratamente il problema cui si
riferisce e, allo stesso tempo, abbastanza semplice da renderlo trattabile con gli strumenti risolutivi disponibili.

L'ottimizzazione è spesso un processo iterativo, in cui il modello matematico di riferimento viene continuamente
raffinato, con l'obiettivo di ottenere soluzioni sempre più accurate, in relazione al problema del mondo reale a cui è
associato.

Oggi siamo in grado di ottimizzare problemi che coinvolgono un numero di variabili e di vincoli molto elevato. Tuttavia,
esistono classi di problemi che non posso essere risolti all'ottimo in un tempo ragionevole e che hanno determinato lo
sviluppo di algoritmi euristici, con la finalità di ottenere soluzioni accettabili in tempi contenuti.


\section{Problemi di Ottimizzazione}\label{sec:opt_prob}
Un problema di ottimizzazione \( \mathcal{P} \) può essere definito con la formulazione generale
\begin{equation}\label{eq:opt_prob}
    \mathcal{P}\colon
    \begin{cases}
        \text{$\min$ (or $\max$)} & f(\vec{x}) \\
                                  & \mathcal{S} \\
                                  & \vec{x} \in \mathcal{D}
    \end{cases}
\end{equation}
dove
\(
    f(\vec{x})
\)
è una funzione a valori reali nelle variabili
\(
    \vec{x} = [x_1 \, \ldots \, x_n]^{\tr} \in \mathcal{D} = D_1 \times \dots \times D_n,
\)
con
\(
    x_j \in D_j \;\; \forall j \colon 1 \leq j \leq n
\)
e
\(
    \mathcal{S}
\)
è un insieme finito di vincoli. Formalmente, un vincolo
\(
    c \in \mathcal{S}
\)
è una funzione che coinvolge un sottoinsieme delle variabili del problema e che può assumere i valori vero o falso,
corrispondenti alle condizioni di vincolo soddisfatto o violato, rispettivamente.

Calcolare il massimo di una funzione
\(
    f(\vec{x})
\)
è equivalente a calcolare il minimo della funzione
\(
    -f(\vec{x})
\). Infatti, i due valori coincidono, a meno del segno, e si ottengono nello stesso punto
\(
    \bar{\vec{x}}
\).
Di conseguenza, nel seguito possiamo limitarci a studiare i problemi di minimo senza perdere di generalità. Tutte le
considerazioni saranno valide, eventualmente con opportune modifiche, anche per i problemi di massimo.
\begin{defbox}{}{sol}
    Sia \( \mathcal{P} \) un problema di ottimizzazione della forma presentata in \eqref{eq:opt_prob}. Ogni \( \vec{x}
    \in D \) si dice soluzione di \( \mathcal{P} \). Una soluzione che soddisfi tutti i vincoli in \( \mathcal{S} \) si
    dice ammissibile per \( \mathcal{P} \).
\end{defbox}
Per riferirci all'insieme di tutte le soluzioni ammissibili di un problema di ottimizzazione
\(
    \mathcal{P},
\)
utilizzeremo la notazione
\(
    F(\mathcal{P}).
\)
Il dominio \( \mathcal{D} \) fornisce una classificazione immediata dei problemi di ottimizzazione.

\begin{itemize}
    \item Se \( \mathcal{D} \) è un insieme discreto, allora il problema è detto di \textit{ottimizzazione discreta}.
    \item Se \( \mathcal{D} \) è un insieme continuo, allora il problema è detto di \textit{ottimizzazione continua}.
\end{itemize}
Inoltre, nel caso particolare di un dominio
\(
    \mathcal{D}
\)
che sia un insieme discreto e finito, si parla di \textit{ottimizzazione combinatoria}.
\begin{defbox}{Soluzione Ottima}{optsol}
    Sia \( \mathcal{P} \) un problema di ottimizzazione della forma presentata in \eqref{eq:opt_prob}. Una soluzione
    ammissibile \( \vec{x^{\star}} \in F(\mathcal{P}) \) si dice ottima per \( \mathcal{P} \) se
    \[
        f(\vec{x^{\star}}) \leq f(\vec{x}) \quad \forall \vec{x} \in F(\mathcal{P}).
    \]
\end{defbox}
Un problema di ottimizzazione \( \mathcal{P} \) si dice impossibile (\textit{infeasible}) quando
\(
    F(\mathcal{P}) = \varnothing.
\)
Diciamo invece che
\(
    \mathcal{P}
\)
è illimitato (\textit{unbounded}) quando non esiste alcun limite inferiore a \( f(\vec{x}) \), per \( \vec{x} \in
F(\mathcal{P}) \). Se esiste una soluzione \( \vec{x^{\star}} \in F(\mathcal{P}) \) ottima, allora
diciamo che \( \mathcal{P} \) ammette ottimo finito.

La funzione \( f(\vec{x}) \) è chiamata funzione obiettivo e il valore \( f(\bar{\vec{x}}) \) è tipicamente noto come
costo associato alla soluzione \( \bar{\vec{x}} \in F(\mathcal{P}) \).

Infine, un problema di ottimizzazione si dice risolto quando si trova una soluzione ottima, e si dimostra che è tale,
oppure quando si dimostra che il problema è impossibile o illimitato.

\subsection{Restrizioni e Rilassamenti}

\begin{defbox}{Restrizione}{restr}
    Sia \( \mathcal{P} \) un problema di ottimizzazione. Si definisce restrizione di \( \mathcal{P} \) un problema di
    ottimizzazione \( \mathcal{P}' \) ottenuto da \( \mathcal{P} \) aggiungendo vincoli.
\end{defbox}

Intuitivamente, aggiungere vincoli ad un problema significa ridurre lo spazio delle sue soluzioni ammissibili.
Formalmente, se \( \mathcal{P}' \) è una restrizione di \( \mathcal{P} \), allora \( F(\mathcal{P}') \subseteq
F(\mathcal{P}) \). Di conseguenza, se \( \bar{\vec{x}} \) è una generica soluzione ammissibile per \( \mathcal{P}' \),
ossia \( \bar{\vec{x}} \in F(\mathcal{P}')\), allora \( \bar{\vec{x}} \) è ammissibile per \( \mathcal{P} \), cioè \(
\bar{\vec{x}} \in F(\mathcal{P}) \). Inoltre, è facile verificare che il costo associato a \( \bar{\vec{x}} \in
F(\mathcal{P}') \) fornisce
un limite superiore (\textit{upper bound}) al valore ottimo di \( \mathcal{P} \), ossia
\(
    f(\vec{x^{\star}}) \leq f(\vec{\bar{x}}),
\)
dove \( \vec{x^{\star}} \in F(\mathcal{P}) \) rappresenta una soluzione ottima per \( \mathcal{P} \).

Infine, poiché \( F(\mathcal{P}') \subseteq F(\mathcal{P}) \), si dimostra immediatamente che se \( \mathcal{P} \) è
impossibile, cioè \( F(\mathcal{P}) = \varnothing \), allora anche ogni sua restrizione \( \mathcal{P}' \) è
impossibile, ossia \( F(\mathcal{P}') = \varnothing \). Non vale il viceversa.

\begin{defbox}{Rilassamento}{rilass}
    Sia \( \mathcal{P} \) un problema di ottimizzazione. Si definisce rilassamento di \( \mathcal{P} \) un problema di
    ottimizzazione \( \mathcal{R} \) ottenuto da \( \mathcal{P} \) rimuovendo vincoli e/o sostituendo la funzione
    obiettivo \( f(\vec{x}) \) di \( \mathcal{P} \) con una sua approssimazione inferiore \( g(\vec{x}) \). Formalmente,
    \( \mathcal{R} \) è un rilassamento di \( \mathcal{P} \) se
    \begin{itemize}
        \item \( F(\mathcal{P}) \subseteq F(\mathcal{R}) \),
        \item \( g(\vec{x}) \leq f(\vec{x}) \), \( \forall \vec{x} \in F(\mathcal{P}) \).
    \end{itemize}
\end{defbox}
Si verifica immediatamente che se \( \mathcal{R} \) è impossibile, ossia
\(
    F(\mathcal{R}) = \varnothing,
\)
allora anche \( \mathcal{P} \) è impossibile, cioè \( F(\mathcal{P}) = \varnothing \). Non vale il viceversa. Inoltre, è
facile dimostrare che se \( \bar{\vec{x}} \in F(\mathcal{R}) \) è soluzione ottima per \( \mathcal{R} \), allora \(
g(\bar{\vec{x}}) \) fornisce un limite inferiore (\textit{lower bound}) al valore ottimo di \( \mathcal{P} \).
Formalmente risulta \( f(\vec{x^{\star}}) \geq g(\bar{\vec{x}}) \), dove
\(
    \vec{x^{\star}} \in F(\mathcal{P})
\)
è soluzione ottima di
\(
    \mathcal{P}.
\)

Infine, se la soluzione ottima \( \vec{x^{\star}} \in F(\mathcal{R}) \) di \( \mathcal{R} \) è ammissibile per \(
\mathcal{P} \), con \( g(\vec{x^{\star}}) = f(\vec{x^{\star}}) \), allora \( \vec{x^{\star}} \) è soluzione ottima per
\( \mathcal{P} \).

\subsection{Ricerca}

Dato un problema di ottimizzazione \( \mathcal{P} \), la ricerca è il processo che consiste nel risolvere una sequenza
finita
\(
    \mathcal{P}_1, \ldots, \mathcal{P}_m
\)
di restrizioni di \( \mathcal{P} \). L'idea alla base della ricerca è quella di aggiungere vincoli al problema di
partenza per ottenere delle restrizioni che siano più semplici da risolvere. Le soluzioni
delle restrizioni possono poi essere utilizzate per ottenere una soluzione di \( \mathcal{P} \).

\begin{defbox}{Ricerca Esaustiva}{search}
    Siano \( \mathcal{P} \) un problema di ottimizzazione e \( \mathcal{P}_1, \ldots, \mathcal{P}_m \) una sequenza di
    restrizioni. Si definisce ricerca esaustiva il processo di ricerca che esplora tutto lo spazio delle soluzioni
    ammissibili di \( \mathcal{P} \). Formalmente, deve valere
    \[
        \bigcup_{i = 1}^m F(\mathcal{P}_i) = F(\mathcal{P}).
    \]
\end{defbox}
Una ricerca non esaustiva si dice euristica. Una ricerca esaustiva permette di risolvere un problema di ottimizzazione
\( \mathcal{P} \) trovando le soluzioni di tutte le restrizioni
\(
    \mathcal{P}_i
\)
e scegliendo quella migliore.

La forma più semplice di ricerca esaustiva prende il nome di \textit{generate-and-test} e consiste nel generare
esplicitamente tutte le soluzioni \( \vec{x} \in \mathcal{D} \) di \( \mathcal{P} \), verificare quali soddisfano i
vincoli del problema e scegliere tra queste quella migliore. Questa strategia è applicabile in pratica solo a una classe
ristretta di problemi di ottimizzazione e in generale non è molto efficiente.

Una tipologia di ricerca migliore è quella che viene chiamata \textit{tree-search} e che sfrutta una struttura ad albero
per esplorare lo spazio delle soluzioni ammissibili di un problema. Questo tipo di ricerca è alla base di molti
algoritmi che vengono utilizzati nella pratica per risolvere problemi di ottimizzazione. L'idea è quella di dividere
ricorsivamente lo spazio di ricerca delle soluzioni ammissibili di \( \mathcal{P} \), creando delle restrizioni in modo
da formare una struttura ad albero, in cui i nodi foglia corrispondono a restrizioni sufficientemente facili da
risolvere direttamente. Una ricerca di questo tipo è spesso combinata con il concetto di rilassamento, con l'obiettivo
di facilitare la risoluzione delle restrizioni associate ai vari nodi dell'albero.

Infine, è importante precisare che una ricerca esaustiva non è necessariamente l'approccio risolutivo migliore in tutte
le situazioni. Esistono classi di problemi per cui ha poco senso provare a trovare una soluzione ottima, ad esempio
perché esplorare per intero lo spazio delle soluzioni ammissibili richiederebbe un tempo di computazione troppo elevato.
Di conseguenza, in queste situazioni è molto più utile utilizzare algoritmi euristici, il cui obiettivo è quello di
fornire una soluzione accettabile in tempi ragionevoli.

\section{Programmazione Lineare}
La programmazione lineare costituisce uno dei paradigmi fondamentali nell'ambito dell'ottimizzazione, poichè si applica
in modo naturale ad un'ampia classe di problemi del mondo reale, che risultano quindi facili da modellare. Nel corso del
tempo, vari algoritmi sono stati sviluppati con l'obiettivo di risolvere in maniera efficiente problemi di
programmazione lineare che coinvolgono un numero elevato di variabili e vincoli.

Un problema di programmazione lineare (\textit{Linear Program}, LP), è un problema di ottimizzazione in cui la funzione
obiettivo e i vincoli sono funzioni lineari. Per un problema di programmazione lineare \( \mathcal{P} \) con \( n \)
variabili e \( m \) vincoli si può utilizzare la formulazione generale

\begin{equation}
\mathcal{P}\colon
\setlength{\arraycolsep}{2pt}
\left\{\begin{array}{rrcccccc}
\min & z\,\, &=& \multicolumn{5}{c}{c_{1}\,x_{1}+\cdots+c_{n}\,x_{n}} \\[15pt]
     &  a_{11}\,x_{1} &+ &\cdots &+ &a_{1n}\,x_{n} &\sim &b_{1}       \\
     & \multicolumn{1}{c}{\vdots} &&\ddots&&\vdots&& \vdots           \\
     &  a_{m1}\,x_{1} &+ &\cdots &+ &a_{mn}\,x_{n} &\sim &b_{m}       \\[15pt]
     & \multicolumn{7}{l}{\ell_j \le x_{j} \le u_{j} \;\;\, \forall j\colon
     1 \le j \le n}
\end{array}\right.\\[10pt]
\end{equation}
dove
\(
\sim \,\,\in \{ \leq, =, \geq \}, \text{ } \ell_j \in \mathbb{R} \cup \{-\infty\} \text{ e } u_j \in \mathbb{R} \cup
\{+\infty\},
\)
con \( c_k \in \mathbb{R} \;\, \forall k\colon 1 \leq k \leq n \), \( a_{ij} \in \mathbb{R} \;\, \forall i,j\colon 1
\leq i \leq m,\, 1 \leq j \leq n \) e \( b_i \in \mathbb{R}\;\, \forall i\colon 1 \leq i \leq m \). Le variabili del
problema hanno come dominio intervalli (eventualmente illimitati) di \( \mathbb{R} \) e la funzione obiettivo può essere
scritta nella forma compatta
\begin{equation}
    z = \sum_{k = 1}^n c_k\,x_k\,.
\end{equation}
Similmente, il generico vincolo può essere scritto come
\begin{equation}
    \sum_{j = 1}^n a_{ij}\, x_j \sim b_i \qquad \forall i\colon 1 \leq i \leq m.
\end{equation}

La proprietà di linearità di funzione obiettivo e vincoli permette di utilizzare la teoria dell'analisi convessa come
base nello sviluppo di algoritmi risolutivi per problemi di programmazione lineare. In aggiunta, questa proprietà
semplifica significativamente il processo attraverso cui è possibile ottenere formulazioni alternative, tutte
equivalenti tra loro, relativamente ad uno stesso problema di programmazione lineare.

\subsection{Formulazioni Equivalenti}
Uno stesso problema di programmazione lineare può essere espresso attraverso molteplici formulazioni differenti, tutte
equivalenti tra loro. Inoltre, con le opportune trasformazioni, è sempre possibile passare da una formulazione
all'altra. Per il generico problema di programmazione lineare
\(
    \mathcal{P}
\)
con \( n \) variabili e \( m \) vincoli, le due forme maggiormente utilizzate sono la forma standard e quella canonica,
riportate di seguito.

\begin{subequations}
\hspace*{.1\textwidth}
\begin{minipage}{.3\textwidth}
\begin{align}\notag
    \begin{cases}
        \,\min & \vec{c}^{\tr} \vec{x} \\
               & \vec{A} \vec{x} = \vec{b} \\\label{eq:LPstd}
             & \vec{x} \ge 0
    \end{cases}\\[7pt] \text{Forma Standard}
\end{align}
\end{minipage}\hspace{.1\textwidth}
\begin{minipage}{.3\textwidth}
    \begin{align}\notag
    \begin{cases}
        \,\min & \vec{c}^{\tr} \vec{x} \\
               & \vec{A} \vec{x} \ge \vec{b} \\\label{eq:LPcanonical}
             & \vec{x} \ge 0
    \end{cases}\\[7pt] \text{Forma Canonica}
\end{align}
\end{minipage}
\end{subequations}\\[10pt]
dove \( \vec{x} \in \mathbb{R}^n \), con \( \vec{c} \in \mathbb{R}^n \), \( \vec{A} \in \mathbb{R}^{m\times n} \) e \(
\vec{b} \in \mathbb{R}^m \). Le trasformazioni necessarie per passare da una forma all'altra consistono
nell'introduzione di variabili ausiliarie e la convenienza nell'utilizzare una forma piuttosto che un'altra dipende
dallo specifico contesto applicativo.

\subsection{Interpretazione Geometrica}
Prima di analizzare un problema di programmazione lineare dal punto di vista geometrico, è essenziale introdurre alcuni
concetti.

\begin{defbox}{Insieme Convesso}{convset}
    Un insieme \( \mathcal{C} \) si dice convesso se
    \(
        \lambda x_1 + (1 - \lambda) x_2 \in \mathcal{C} \quad \forall x_1, x_2 \in \mathcal{C}, \text{ con } \lambda
        \in [0, 1].
    \)
\end{defbox}
Intuitivamente, un insieme è convesso se, per ogni coppia di punti al suo interno, il segmento che li unisce è
completamente contenuto nell’insieme. La definizione \ref{def:convset} può essere generalizzata per un numero finito \(
x_1, \ldots, x_k \) di punti in \( \mathcal{C} \). In questo caso, rimane definita la combinazione lineare
convessa
\begin{equation}
    \sum_{i=1}^k \lambda_i x_i\,, \qquad\sum_{i=1}^k \lambda_i = 1\,.
\end{equation}
Questa generalizzazione permette di enunciare il seguente teorema.
\begin{thmbox}{}{convexcombthm}
    Un insieme \( \mathcal{C} \) è convesso se e solo se tutte le combinazioni lineari convesse di punti in \(
    \mathcal{C} \) sono contenute in \( \mathcal{C} \).
\end{thmbox}
Esempi di insiemi convessi sono gli iperpiani \( \{\vec{x} \in \mathbb{R}^n \mid \vec{a}^{\tr} \vec{x} = a_0\} \), e i
semispazi chiusi \( \{\vec{x} \in \mathbb{R}^n \mid \vec{a}^{\tr} \vec{x} \leq a_0\} \), con \( \vec{a} \in \mathbb{R}^n
\) e \( a_0 \in \mathbb{R} \).
\begin{thmbox}{}{convexintersection}
    L'intersezione di un numero finito di iperpiani e semispazi chiusi è un insieme convesso che viene chiamato poliedro.
\end{thmbox}
Un poliedro limitato viene chiamato politopo. Di conseguenza, lo spazio delle soluzioni ammissibili di un problema di
programmazione lineare è un insieme convesso, poichè è l'intersezione di vincoli lineari (iperpiani o semispazi chiusi).

La definizione di un politopo come intersezione di iperpiani e semispazi chiusi è detta descrizione esterna. Esiste una
modalità alternativa di definire un politopo, chiamata descrizione interna, che si basa sul concetto di vertice definito
di seguito.

\begin{defbox}{Vertice}{vertex}
   Si dice vertice di un poliedro un punto che non può essere espresso come combinazione lineare convessa stretta di
   altri due punti del poliedro.
\end{defbox}

Questa definizione ci permette di formalizzare la descrizione interna di un politopo.

\begin{thmbox}{Descrizione Interna di un Politopo}{intdesc}
    Siano \( \mathcal{P} \) un politopo di \( \mathbb{R}^n \) e \( \mathcal{V} = \{\vec{x}_1, \ldots, \vec{x}_k\} \)
    l'insieme dei suoi vertici. Allora ogni punto di \( \mathcal{P} \) può essere espresso come combinazione lineare
    convessa dei punti in \( \mathcal{V} \,\):
    \[
        \vec{x} \in \mathcal{P} \iff \vec{x} = \sum_{i=1}^k \lambda_i \vec{x}_i\,,\quad  \sum_{i=1}^k \lambda_i =
        1,\;\, \lambda_i \geq 0 \;\;\, \forall i\colon 1 \leq i \leq k.
    \]
\end{thmbox}
La descrizione interna di un politopo è uno strumento importante perché permette di dimostrare il teorema fondamentale
della programmazione lineare, riportato di seguito.

\begin{thmbox}{Teorema Fondamentale della Programmazione Lineare}{thmLP}
    Consideriamo il problema di programmazione lineare \( \min\{\vec{c}^{\tr}\vec{x} \mid \vec{x} \in \mathcal{P}\} \),
    dove \( \mathcal{P} = \{\vec{x} \in \mathbb{R}^n \mid \vec{A}\vec{x} \leq \vec{b}\} \) è il politopo che rappresenta
    la regione ammissibile, con \( \vec{A} \in \mathbb{R}^{m\times n}, \, \vec{b} \in \mathbb{R}^m \) e \( \vec{c} \in
    \mathbb{R}^n \). Allora, se il problema ammette ottimo finito, esiste almeno un vertice di \( \mathcal{P} \) che è
    soluzione ottima.
\end{thmbox}

Questo teorema ci fornisce un modo concreto per risolvere un problema di programmazione lineare, che consiste nel limitare
la ricerca della soluzione ottima all'insieme dei vertici del politopo che definisce la regione ammissibile.

Il teorema può essere esteso al caso generale di problemi di programmazione lineare in cui la regione ammissibile è un
poliedro (con almeno un vertice), e non necessariamente un politopo. L'ipotesi sull'esistenza della soluzione ottima
deve comunque valere, per evitare che il problema possa risultare illimitato o impossibile.

\subsection{Algoritmo del Simplesso}
L'algoritmo del simplesso è uno degli algoritmi maggiormente impiegati nell'ambito dell'ottimizzazione per risolvere
problemi di programmazione lineare. \`E un algoritmo iterativo che cerca di sfruttare il teorema fondamentale della
programmazione lineare in modo intelligente, con l'obiettivo ridurre il numero dei vertici da ispezionare per trovare la
soluzione ottima. L'idea è quella di partire da un vertice arbitrario del poliedro che definisce la regione ammissibile
e di muoversi ad ogni iterazione in un vertice adiacente non peggiore, relativamente al valore della funzione obiettivo.

\`E importante precisare che nonostante l'algoritmo del simplesso scelga di spostarsi tra i vertici in modo
intelligente, non c'è alcuna garanzia che il vertice corrispondente alla soluzione ottima venga trovato prima di aver
ispezionato tutti gli altri vertici del politopo. Per questo motivo, si può dimostrare che la complessità computazionale
al caso peggiore è esponenziale.

\subsection{Dualità}
All'inizio della sezione \ref{sec:opt_prob} abbiamo argomentato che per dichiarare risolto un problema di
ottimizzazione, non è sufficiente trovare una soluzione ottima, ma è necessario fornire una dimostrazione
che attesti l'ottimalità di tale soluzione, relativamente al problema considerato.

Per i problemi di programmazione lineare esiste un modo elegante e rigoroso per certificare l'ottimalità di una
soluzione, che utilizza un problema di ottimizzazione di supporto chiamato problema duale. Il problema duale è ottenuto
a partire dal problema iniziale che, in questo contesto, prende il nome di problema primale. L'idea di base è quella di
combinare i vincoli del problema primale per costruire una limitazione al valore della sua funzione obiettivo. Questo
concetto può essere compreso meglio attraverso un esempio di carattere generale, che viene riportato di seguito.

Sia $\mathcal{P}$ un problema di programmazione lineare con $n$ variabili e
$m$ vincoli. Senza perdita di generalità, possiamo assumere che
$\mathcal{P}$ sia espresso nella forma standard \eqref{eq:LPstd} oppure in
quella canonica \eqref{eq:LPcanonical}. Ad esempio, sia $\mathcal{P}$ della
forma
\begin{equation}\label{eq:canonicalduality}
    \mathcal{P}\colon
    \begin{cases}
        \,\min & \vec{c}^{\tr} \vec{x} \\
               & \vec{A} \vec{x} \ge \vec{b} \\
             & \vec{x} \ge 0
    \end{cases}\\[5pt]
\end{equation}
dove $\vec{x} \in \mathbb{R}^n$, con $\vec{c} \in \mathbb{R}^n,\ \vec{A} \in \mathbb{R}^{m \times n}$ e $\vec{b} \in
\mathbb{R}^m$. Supponiamo che \( \vec{x^{\star}} \) sia la soluzione ottima candidata. Per certificare l'ottimalità
dobbiamo dimostrare che non esistono soluzioni migliori. Nel caso di un problema di minimo, questo significa verificare
che \( \vec{x^{\star}} \) è la soluzione di costo minimo.

Per la generica soluzione ammissibile \( \vec{x} \in F(\mathcal{P}) \) vale \( \vec{A}\vec{x} \geq \vec{b} \). Allora,
introducendo un vettore \( \vec{u} \in \mathbb{R}^m, \vec{u} \geq 0 \), chiamato vettore di moltiplicatori, risulta che
\begin{equation}\label{eq:u}
    \vec{u}^{\tr}\vec{A}\vec{x} \geq \vec{u}^{\tr}\vec{b}.
\end{equation}
Inoltre, possiamo costruire \( \vec{u} \) in modo che valga \( \vec{c}^{\tr} \geq \vec{u}^{\tr} \vec{A} \), da cui,
usando la \eqref{eq:u}, si trova
\begin{equation}\label{eq:cxuax}
    \vec{c}^{\tr}\vec{x} \geq \vec{u}^{\tr}\vec{A}\vec{x} \geq \vec{u}^{\tr}\vec{b} \quad \forall \vec{x} \in
    F(\mathcal{P}),
\end{equation}
essendo \( \vec{x} \geq 0 \). In altre parole, possiamo utilizzare \( \vec{u} \) per creare una combinazione lineare dei
vincoli di \( \mathcal{P} \) che costituisca una limitazione inferiore al valore della funzione obiettivo. A questo
punto, dobbiamo scegliere \( \vec{u} \) in modo da ottenere la limitazione inferiore migliore, cioè quella più alta
possibile. In effetti, questo significa risolvere il problema di programmazione lineare
\begin{equation}\label{eq:dual}
    \mathcal{D}\colon
    \begin{cases}
        \,\max & \vec{u}^{\tr} \vec{b} \\
               & \vec{u}^{\tr}\vec{A} \le \vec{c}^{\tr} \\
             & \vec{u} \ge 0
    \end{cases}\\[7pt]
\end{equation}
nelle variabili \( \vec{u} = [u_1 \ldots u_m]^{\tr} \in \mathbb{R}^m \), con \( \mathcal{D} \) che prende il nome di
problema duale di \( \mathcal{P} \).
Con qualche modifica, il ragionamento si applica identicamente a problemi espressi nella forma standard. In maniera del
tutto simmetrica, può essere applicato a problemi di massimo.

Le disuguaglianze \eqref{eq:u} e \eqref{eq:cxuax} hanno una conseguenza immediata, riassunta nel teorema riportato di
seguito, detto teorema della dualità debole.

\begin{thmbox}{Dualità Debole}{weakduality}
    Siano \( \mathcal{P} \) un problema di programmazione lineare come in \eqref{eq:canonicalduality} e \( \mathcal{D}
    \) il suo problema duale, come in \eqref{eq:dual}. Allora, per le generiche soluzioni ammissibili \( \vec{x} \text{
    e } \vec{u} \) di \( \mathcal{P} \) e \( \mathcal{D} \), rispettivamente, risulta
    \[
        \vec{c}^{\tr} \vec{x} \geq \vec{b}^{\tr}\vec{u}.
    \]
    Inoltre, se vale
    \(
        \vec{c}^{\tr} \vec{x} = \vec{b}^{\tr}\vec{u},
    \)
    allora \( \vec{x} \) e \( \vec{u} \) sono soluzioni ottime di \( \mathcal{P} \) e \( \mathcal{D} \),
    rispettivamente.
\end{thmbox}
In altre parole, per un problema di minimo, il costo di una soluzione ammissibile del problema primale è sempre maggiore
o uguale al costo di una soluzione ammissibile del problema duale. Quando i due costi coincidono, allora le due
soluzioni sono ottime. Naturalmente, il teorema è valido simmetricamente per problemi di massimo.

Infine, enunciamo il teorema della dualità forte, che fornisce un modo concreto di certificare l'ottimalità della
soluzione di un problema di programmazione lineare.

\begin{thmbox}{Dualità Forte}{strongduality}
    Consideriamo una coppia primale - duale di problemi di programmazione
    lineare. Allora, se uno dei due ammette ottimo finito, anche l'altro
    ammette ottimo finito e il valore ottimo della funzione obiettivo è lo
    stesso per entrambi.
\end{thmbox}
Di conseguenza, per verificare l'ottimalità della soluzione \( \vec{x^{\star}} \) del problema primale \( \mathcal{P}
\), è sufficiente determinare una soluzione ammissibile \( \vec{u^{\star}} \) del problema duale \( \mathcal{D} \), in
modo che risulti
\begin{equation}\label{eq:optcond}
    \vec{c}^{\tr}\vec{x^{\star}} = \vec{b}^{\tr}\vec{u^{\star}}.
\end{equation}
Se una tale soluzione \( \vec{u^{\star}} \) esiste, allora \( \vec{x^{\star}} \) è ottima per \( \mathcal{P} \) e \(
\vec{u^{\star}} \) è ottima per \( \mathcal{D} \). Al contrario, l'inesistenza di \( \vec{u^{\star}} \) ammissibile per
\( \mathcal{D} \) che soddisfi la \eqref{eq:optcond} dimostra che \( \vec{x^{\star}} \) non è ottima per \( \mathcal{P}
\).

\subsection{Rilassamento Lagrangiano}

In alcune situazioni la formulazione di un problema di programmazione lineare può essere abbastanza complessa da
impedire l'applicazione diretta di un algoritmo risolutivo. In questi casi può essere utile provare a trasformarla in
una formulazione differente, con l'obiettivo di ottenere un problema più facile da risolvere. Alcune volte il problema
associato alla formulazione alternativa è equivalente a quello iniziale e ha lo stesso valore ottimo. Altre volte non siamo
così fortunati, e le due formulazioni non sono equivalenti. Di conseguenza, la formulazione alternativa non è sempre
sufficiente per risolvere direttamente il problema di partenza, ma risulta comunque utile per ottenere delle limitazioni
alla sua funzione obiettivo.

L'intuizione alla base del rilassamento Lagrangiano è quella di semplificare un problema rimuovendo alcuni dei suoi
vincoli e aggiungendo un contributo alla funzione obiettivo. Questo contributo, che prende il nome di penalizzazione
Lagrangiana, è ottenuto a partire dai vincoli eliminati e serve a peggiorare il valore della funzione obiettivo per
soluzioni che non li soddisfano.
A questo punto possiamo formalizzare questo concetto, limitandoci ad analizzare gli aspetti fondamentali che riflettono
gli obiettivi di questo lavoro.

Sia $\mathcal{P}$ un generico problema di programmazione lineare, espresso
nella forma canonica
\begin{equation}
    \mathcal{P}\colon
    \begin{cases}
        \,\min & \vec{c}^{\tr} \vec{x} \\
               & \vec{A} \vec{x} \ge \vec{b} \\
             & \vec{x} \ge 0
    \end{cases}
\end{equation}
dove $\vec{x} \in \mathbb{R}^n$, con $\vec{c} \in \mathbb{R}^n,\ \vec{A}
\in \mathbb{R}^{m \times n}$ e $\vec{b} \in \mathbb{R}^m$. Introduciamo un vettore \( \vec{u} \in \mathbb{R}^m, \vec{u}
\geq 0\) di moltiplicatori, chiamati moltiplicatori di Lagrange, e definiamo la funzione
\begin{equation}
    L(\vec{x}, \vec{u}) = \vec{c}^{\tr} \vec{x} + \vec{u}^{\tr}(\vec{b} - \vec{A}\vec{x}),
\end{equation}
che prende il nome di funzione Lagrangiana di \( \mathcal{P} \). Questa funzione ci permette di definire la famiglia di
problemi Lagrangiani della forma
\begin{equation}
    \mathcal{L}(\vec{u})\colon
    \begin{cases}
        \min & \vec{c}^{\tr} \vec{x} + \vec{u}^{\tr}(\vec{b} - \vec{A}\vec{x}) = L(\vec{x}, \vec{u})\\
             & \vec{x} \geq 0
    \end{cases}
\end{equation}
che sono sempre un rilassamento di \( \mathcal{P} \) e quindi forniscono un limite inferiore al valore ottimo della sua
funzione obiettivo. Utilizzando una forma più compatta, possiamo scrivere
\begin{equation}
    \mathcal{L}(\vec{u}) = \min_{\vec{x} \,\geq\, 0} \,L(\vec{x}, \vec{u}) = \min_{\vec{x} \,\geq\, 0}\,\{\vec{c}^{\tr}
    \vec{x} + \vec{u}^{\tr}(\vec{b} - \vec{A}\vec{x}) \},
\end{equation}
con \( \mathcal{L}(\vec{u}) \) che viene chiamata funzione duale di \( \mathcal{P} \). Per trovare la migliore
limitazione inferiore al valore ottimo di \( \mathcal{P} \), dobbiamo risolvere all'ottimo il problema duale Lagrangiano
\begin{equation}
    \mathcal{D}\colon
    \begin{cases}
        \max & \mathcal{L}(\vec{u}) \\
             & \vec{u} \geq 0
    \end{cases}
\end{equation}
Inoltre, si può dimostrare che se \( \mathcal{P} \) ammette ottimo finito, allora il valore ottimo della sua funzione
obiettivo coincide con il costo di una soluzione ottima del problema duale Lagrangiano \( \mathcal{D} \). Questo
risultato costituisce la base teorica dell'algoritmo risolutivo che viene implementato nel capitolo \ref{chap:impl} e
che si basa sul metodo di Frank-Wolfe, approfondito nel seguito. In particolare, risolveremo il problema duale
Lagrangiano e, sfruttando la proprietà appena presentata, saremo in grado di trovare una limitazione inferiore al valore
ottimo del problema iniziale.

\section{Programmazione Lineare Intera}
Il paradigma della programmazione lineare intera è un estensione della programmazione lineare che aggiunge la
possibilità di vincolare le variabili ad assumere valori interi. Il generico problema di programmazione lineare intera
\( \mathcal{P} \) con \( n \) variabili e \( m \) vincoli può essere definito con la formulazione generale
\begin{equation}
\mathcal{P}\colon
\setlength{\arraycolsep}{2pt}
\left\{\begin{array}{rrcccccc}
\min & z\,\, &=& \multicolumn{5}{c}{c_{1}\,x_{1}+\cdots+c_{n}\,x_{n}} \\[15pt]
     &  a_{11}\,x_{1} &+ &\cdots &+ &a_{1n}\,x_{n} &\sim &b_{1}       \\
     & \multicolumn{1}{c}{\vdots} &&\ddots&&\vdots&& \vdots           \\
     &  a_{m1}\,x_{1} &+ &\cdots &+ &a_{mn}\,x_{n} &\sim &b_{m}       \\[15pt]
     & \multicolumn{7}{l}{\ell_j \le x_{j} \le u_{j} \;\;\, \forall j\colon 1 \le j \le n} \\[5pt]
     & \multicolumn{7}{l}{x_j \in \mathbb{Z} \;\;\, \forall j \in J \subseteq N = \{ 1, \ldots, n \}}
\end{array}\right.\\[10pt]
\end{equation}
dove
\(
\sim \,\,\in \{ \leq, =, \geq \}, \text{ } \ell_j \in \mathbb{R} \cup \{-\infty\} \text{ e } u_j \in \mathbb{R} \cup
\{+\infty\},
\)
con \( c_k \in \mathbb{R} \;\, \forall k\colon 1 \leq k \leq n \), \( a_{ij} \in \mathbb{R} \;\, \forall i,j\colon 1
\leq i \leq m,\, 1 \leq j \leq n \) e \( b_i \in \mathbb{R}\;\, \forall i\colon 1 \leq i \leq m \).
Quando tutte le variabili sono vincolate ad assumere valori interi, ossia \( J = N \), il problema è detto di
programmazione lineare intera pura. Se invece il vincolo di interezza è applicato solo ad alcune variabili, cioè \( J
\subset N \), il problema è detto di programmazione lineare intera mista. Naturalmente quando \( J = \varnothing \) il
problema diventa un problema di programmazione lineare.

La possibilità di vincolare le variabili ad assumere valori interi permette di modellare molti più problemi del mondo
reale di quanto non si riesca a fare con la semplice programmazione lineare. Il prezzo da pagare è una difficoltà
maggiore nel processo risolutivo. Infatti, per un problema di programmazione lineare intera non valgono molte delle
considerazioni che abbiamo fatto per la programmazione lineare. L'aver introdotto vincoli di interezza non
garantisce più la convessità della regione ammissibile, e neanche le proprietà che costituiscono il fondamento per
l'algoritmo del simplesso. Per questo motivo, nel tempo sono stati sviluppati ulteriori algoritmi, specificatamente
ideati per gestire i vincoli di interezza.

\subsection{Rilassamento Lineare}

Nel risolvere problemi di programmazione lineare intera, è molto importante utilizzare il concetto di rilassamento. Il
rilassamento più intuitivo e naturale per un problema di programmazione lineare intera è il rilassamento lineare. L'idea
è quella di considerare il problema iniziale, ma senza i vincoli di interezza per le variabili che lo richiedono.
Questa semplificazione trasforma il problema iniziale in un problema di programmazione lineare che quindi può essere
risolto con tutti gli strumenti di cui abbiamo già discusso. L'utilità del rilassamento lineare dipende dallo specifico
problema. In alcuni casi il rilassamento è abbastanza forte da fornire una limitazione utile per la funzione obiettivo
del problema iniziale. Nelle situazioni in cui è invece molto debole, viene spesso combinato con i piani di taglio, con
l'obiettivo di ottenere un rilassamento più forte, in grado di fornire una limitazione migliore. Un piano di taglio è un
vincolo che è violato dalla soluzione ottima corrente del rilassamento lineare, ma soddisfatto dalle soluzioni
ammissibili del problema di partenza. Geometricamente si può visualizzare proprio come un taglio all'interno della
regione ammissibile del rilassamento, che però non interseca la regione ammissibile del problema di partenza, ottenuta
considerando i vincoli di interezza. Questo vincolo viene aggiunto al rilassamento lineare per ottenere una limitazione
inferiore migliore. Il processo di aggiunta di piani di taglio può essere iterato per migliorare la soluzione di un
rilassamento lineare e ottenere una limitazione migliore al valore ottimo del problema di partenza. In effetti, questo
è proprio il meccanismo con cui i rilassamenti lineari vengono utilizzati nell'algoritmo Branch \& Cut (B\&C),
specificatamente ideato per risolvere problemi di programmazione lineare intera.
